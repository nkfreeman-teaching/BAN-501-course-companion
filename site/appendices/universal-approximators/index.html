
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Predictive Modeling - Course Companion">
      
      
        <meta name="author" content="Nick Freeman">
      
      
        <link rel="canonical" href="https://nkfreeman-teaching.github.io/BAN-501-course-companion/appendices/universal-approximators/">
      
      
        <link rel="prev" href="../../modules/10-ethics-deployment/">
      
      
        <link rel="next" href="../cnn-architecture/">
      
      
        
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.1">
    
    
      
        <title>Neural Networks as Universal Approximators - BAN 501 Course Companion</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.484c7ddc.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.ab4e12ef.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#deep-dive-neural-networks-as-universal-approximators" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="BAN 501 Course Companion" class="md-header__button md-logo" aria-label="BAN 501 Course Companion" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            BAN 501 Course Companion
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Neural Networks as Universal Approximators
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/nkfreeman-teaching/BAN-501-course-companion" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    nkfreeman-teaching/BAN-501-course-companion
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="BAN 501 Course Companion" class="md-nav__button md-logo" aria-label="BAN 501 Course Companion" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    BAN 501 Course Companion
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/nkfreeman-teaching/BAN-501-course-companion" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    nkfreeman-teaching/BAN-501-course-companion
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Home
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    Modules
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    Modules
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../modules/01-foundations/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    1. Foundations of ML
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../modules/02-regression/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    2. Regression
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../modules/03-classification/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    3. Classification
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../modules/04-ensemble-methods/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    4. Ensemble Methods
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../modules/05-unsupervised/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    5. Unsupervised Learning
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../modules/06-neural-networks/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    6. Neural Networks
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../modules/07-computer-vision/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    7. Computer Vision
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../modules/08-nlp/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    8. NLP
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../modules/09-interpretability/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    9. Interpretability
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../modules/10-ethics-deployment/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    10. Ethics & Deployment
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    Appendices
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    Appendices
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    
  
    Neural Networks as Universal Approximators
  

    
  </span>
  
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    
  
    Neural Networks as Universal Approximators
  

    
  </span>
  
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#introduction" class="md-nav__link">
    <span class="md-ellipsis">
      
        Introduction
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#the-universal-approximation-theorem" class="md-nav__link">
    <span class="md-ellipsis">
      
        The Universal Approximation Theorem
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="The Universal Approximation Theorem">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#statement" class="md-nav__link">
    <span class="md-ellipsis">
      
        Statement
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#intuition-neurons-as-bump-functions" class="md-nav__link">
    <span class="md-ellipsis">
      
        Intuition: Neurons as "Bump" Functions
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#visual-example-approximating-a-square-wave" class="md-nav__link">
    <span class="md-ellipsis">
      
        Visual Example: Approximating a Square Wave
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#important-caveats" class="md-nav__link">
    <span class="md-ellipsis">
      
        Important Caveats
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#example-1-linear-regression" class="md-nav__link">
    <span class="md-ellipsis">
      
        Example 1: Linear Regression
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Example 1: Linear Regression">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#linear-regression-model" class="md-nav__link">
    <span class="md-ellipsis">
      
        Linear Regression Model
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#neural-network-equivalent" class="md-nav__link">
    <span class="md-ellipsis">
      
        Neural Network Equivalent
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#code-demonstration" class="md-nav__link">
    <span class="md-ellipsis">
      
        Code Demonstration
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#key-insight" class="md-nav__link">
    <span class="md-ellipsis">
      
        Key Insight
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#example-2-logistic-regression" class="md-nav__link">
    <span class="md-ellipsis">
      
        Example 2: Logistic Regression
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Example 2: Logistic Regression">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#logistic-regression-model" class="md-nav__link">
    <span class="md-ellipsis">
      
        Logistic Regression Model
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#neural-network-equivalent_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Neural Network Equivalent
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#code-demonstration_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Code Demonstration
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#key-insight_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Key Insight
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#example-3-approximating-step-functions" class="md-nav__link">
    <span class="md-ellipsis">
      
        Example 3: Approximating Step Functions
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Example 3: Approximating Step Functions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#decision-tree-behavior" class="md-nav__link">
    <span class="md-ellipsis">
      
        Decision Tree Behavior
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#neural-network-approximation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Neural Network Approximation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#why-relu-combinations-work" class="md-nav__link">
    <span class="md-ellipsis">
      
        Why ReLU Combinations Work
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#key-insight_2" class="md-nav__link">
    <span class="md-ellipsis">
      
        Key Insight
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#example-4-polynomial-regression" class="md-nav__link">
    <span class="md-ellipsis">
      
        Example 4: Polynomial Regression
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Example 4: Polynomial Regression">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-problem" class="md-nav__link">
    <span class="md-ellipsis">
      
        The Problem
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-solution-hidden-layer-creates-basis-functions" class="md-nav__link">
    <span class="md-ellipsis">
      
        The Solution: Hidden Layer Creates Basis Functions
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#whats-happening-inside" class="md-nav__link">
    <span class="md-ellipsis">
      
        What's Happening Inside
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#key-insight_3" class="md-nav__link">
    <span class="md-ellipsis">
      
        Key Insight
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#the-unifying-framework" class="md-nav__link">
    <span class="md-ellipsis">
      
        The Unifying Framework
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="The Unifying Framework">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#flexibility-trade-offs" class="md-nav__link">
    <span class="md-ellipsis">
      
        Flexibility Trade-offs
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#when-to-use-simpler-models" class="md-nav__link">
    <span class="md-ellipsis">
      
        When to Use Simpler Models
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="When to Use Simpler Models">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#example-decision" class="md-nav__link">
    <span class="md-ellipsis">
      
        Example Decision
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#when-neural-networks-shine" class="md-nav__link">
    <span class="md-ellipsis">
      
        When Neural Networks Shine
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="When Neural Networks Shine">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#example-decision_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Example Decision
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#common-misconceptions" class="md-nav__link">
    <span class="md-ellipsis">
      
        Common Misconceptions
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#reflection-questions" class="md-nav__link">
    <span class="md-ellipsis">
      
        Reflection Questions
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#practice-problems" class="md-nav__link">
    <span class="md-ellipsis">
      
        Practice Problems
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#summary" class="md-nav__link">
    <span class="md-ellipsis">
      
        Summary
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../cnn-architecture/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    CNN Architecture
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../transformer-architecture/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Transformer Architecture
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#introduction" class="md-nav__link">
    <span class="md-ellipsis">
      
        Introduction
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#the-universal-approximation-theorem" class="md-nav__link">
    <span class="md-ellipsis">
      
        The Universal Approximation Theorem
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="The Universal Approximation Theorem">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#statement" class="md-nav__link">
    <span class="md-ellipsis">
      
        Statement
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#intuition-neurons-as-bump-functions" class="md-nav__link">
    <span class="md-ellipsis">
      
        Intuition: Neurons as "Bump" Functions
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#visual-example-approximating-a-square-wave" class="md-nav__link">
    <span class="md-ellipsis">
      
        Visual Example: Approximating a Square Wave
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#important-caveats" class="md-nav__link">
    <span class="md-ellipsis">
      
        Important Caveats
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#example-1-linear-regression" class="md-nav__link">
    <span class="md-ellipsis">
      
        Example 1: Linear Regression
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Example 1: Linear Regression">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#linear-regression-model" class="md-nav__link">
    <span class="md-ellipsis">
      
        Linear Regression Model
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#neural-network-equivalent" class="md-nav__link">
    <span class="md-ellipsis">
      
        Neural Network Equivalent
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#code-demonstration" class="md-nav__link">
    <span class="md-ellipsis">
      
        Code Demonstration
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#key-insight" class="md-nav__link">
    <span class="md-ellipsis">
      
        Key Insight
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#example-2-logistic-regression" class="md-nav__link">
    <span class="md-ellipsis">
      
        Example 2: Logistic Regression
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Example 2: Logistic Regression">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#logistic-regression-model" class="md-nav__link">
    <span class="md-ellipsis">
      
        Logistic Regression Model
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#neural-network-equivalent_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Neural Network Equivalent
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#code-demonstration_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Code Demonstration
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#key-insight_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Key Insight
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#example-3-approximating-step-functions" class="md-nav__link">
    <span class="md-ellipsis">
      
        Example 3: Approximating Step Functions
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Example 3: Approximating Step Functions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#decision-tree-behavior" class="md-nav__link">
    <span class="md-ellipsis">
      
        Decision Tree Behavior
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#neural-network-approximation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Neural Network Approximation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#why-relu-combinations-work" class="md-nav__link">
    <span class="md-ellipsis">
      
        Why ReLU Combinations Work
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#key-insight_2" class="md-nav__link">
    <span class="md-ellipsis">
      
        Key Insight
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#example-4-polynomial-regression" class="md-nav__link">
    <span class="md-ellipsis">
      
        Example 4: Polynomial Regression
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Example 4: Polynomial Regression">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-problem" class="md-nav__link">
    <span class="md-ellipsis">
      
        The Problem
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-solution-hidden-layer-creates-basis-functions" class="md-nav__link">
    <span class="md-ellipsis">
      
        The Solution: Hidden Layer Creates Basis Functions
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#whats-happening-inside" class="md-nav__link">
    <span class="md-ellipsis">
      
        What's Happening Inside
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#key-insight_3" class="md-nav__link">
    <span class="md-ellipsis">
      
        Key Insight
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#the-unifying-framework" class="md-nav__link">
    <span class="md-ellipsis">
      
        The Unifying Framework
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="The Unifying Framework">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#flexibility-trade-offs" class="md-nav__link">
    <span class="md-ellipsis">
      
        Flexibility Trade-offs
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#when-to-use-simpler-models" class="md-nav__link">
    <span class="md-ellipsis">
      
        When to Use Simpler Models
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="When to Use Simpler Models">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#example-decision" class="md-nav__link">
    <span class="md-ellipsis">
      
        Example Decision
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#when-neural-networks-shine" class="md-nav__link">
    <span class="md-ellipsis">
      
        When Neural Networks Shine
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="When Neural Networks Shine">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#example-decision_1" class="md-nav__link">
    <span class="md-ellipsis">
      
        Example Decision
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#common-misconceptions" class="md-nav__link">
    <span class="md-ellipsis">
      
        Common Misconceptions
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#reflection-questions" class="md-nav__link">
    <span class="md-ellipsis">
      
        Reflection Questions
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#practice-problems" class="md-nav__link">
    <span class="md-ellipsis">
      
        Practice Problems
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#summary" class="md-nav__link">
    <span class="md-ellipsis">
      
        Summary
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              
              <article class="md-content__inner md-typeset">
                
                  


  
  


<h1 id="deep-dive-neural-networks-as-universal-approximators">Deep Dive: Neural Networks as Universal Approximators<a class="headerlink" href="#deep-dive-neural-networks-as-universal-approximators" title="Permanent link">&para;</a></h1>
<p><em>Extends Module 6: Neural Networks</em></p>
<hr />
<h2 id="introduction">Introduction<a class="headerlink" href="#introduction" title="Permanent link">&para;</a></h2>
<p>In Module 6, we learned how to build and train neural networks. But there's a deeper question: <em>why</em> can neural networks learn such a wide variety of functions?</p>
<p>The answer lies in the <strong>Universal Approximation Theorem</strong>—one of the most important theoretical results in deep learning. This theorem tells us that neural networks can, in principle, learn <em>any</em> reasonable function.</p>
<p>But here's the surprising part: many classical ML models you already know are actually <strong>special cases</strong> of neural networks. Linear regression, logistic regression, even aspects of decision trees—they're all points on a spectrum of neural network complexity.</p>
<p>This deep dive explores these connections and helps you understand when simple models suffice and when you need the full power of neural networks.</p>
<p><strong>Why research continues</strong>: The Universal Approximation Theorem is an existence result—it guarantees a solution exists but says nothing about finding it. "Enough neurons" might mean exponentially many. The theorem provides no guarantees about training difficulty, data requirements, or generalization. Depth enables compositional learning (f(g(h(x))) is more parameter-efficient than one massive layer). The gap between "theoretically possible" and "practically achievable" drives ongoing research.</p>
<hr />
<h2 id="the-universal-approximation-theorem">The Universal Approximation Theorem<a class="headerlink" href="#the-universal-approximation-theorem" title="Permanent link">&para;</a></h2>
<h3 id="statement">Statement<a class="headerlink" href="#statement" title="Permanent link">&para;</a></h3>
<p><strong>Theorem</strong> (Cybenko, 1989; Hornik, 1991):</p>
<blockquote>
<p>A feedforward neural network with a single hidden layer containing a finite number of neurons can approximate any continuous function on a compact subset of <span class="arithmatex">\(\mathbb{R}^n\)</span> to arbitrary accuracy.</p>
</blockquote>
<p>In simpler terms: <strong>Given enough hidden neurons, a one-hidden-layer neural network can learn any reasonable function.</strong></p>
<h3 id="intuition-neurons-as-bump-functions">Intuition: Neurons as "Bump" Functions<a class="headerlink" href="#intuition-neurons-as-bump-functions" title="Permanent link">&para;</a></h3>
<p>Each hidden neuron with a sigmoid activation creates an S-shaped curve:</p>
<p><img alt="Sigmoid Curves" src="../../assets/deep_dive/sigmoid_curves.png" /></p>
<p>By combining multiple neurons:
- Two sigmoids can create a "bump" (rise then fall)
- Many bumps can approximate any shape
- The more neurons, the smoother the approximation</p>
<h3 id="visual-example-approximating-a-square-wave">Visual Example: Approximating a Square Wave<a class="headerlink" href="#visual-example-approximating-a-square-wave" title="Permanent link">&para;</a></h3>
<p><img alt="Neuron Approximation" src="../../assets/deep_dive/neuron_approximation.png" /></p>
<h3 id="important-caveats">Important Caveats<a class="headerlink" href="#important-caveats" title="Permanent link">&para;</a></h3>
<p>The theorem tells us approximation is <strong>possible</strong>, but NOT:
1. <strong>How many neurons</strong> are needed (could be astronomically large)
2. <strong>How to find</strong> the right weights (training might fail)
3. <strong>How much data</strong> is required (might need infinite samples)
4. <strong>Whether it will generalize</strong> (might just memorize)</p>
<hr />
<h2 id="example-1-linear-regression">Example 1: Linear Regression<a class="headerlink" href="#example-1-linear-regression" title="Permanent link">&para;</a></h2>
<p><strong>The simplest case</strong>: Neural networks can perform linear regression exactly.</p>
<h3 id="linear-regression-model">Linear Regression Model<a class="headerlink" href="#linear-regression-model" title="Permanent link">&para;</a></h3>
<div class="arithmatex">\[\hat{y} = w_1 x_1 + w_2 x_2 + b\]</div>
<p>For example: <span class="arithmatex">\(\hat{y} = 2x_1 + 3x_2 + 1\)</span></p>
<h3 id="neural-network-equivalent">Neural Network Equivalent<a class="headerlink" href="#neural-network-equivalent" title="Permanent link">&para;</a></h3>
<p>A neural network with:
- <strong>No hidden layers</strong>
- <strong>Linear activation</strong> (or no activation function)
- <strong>Single output neuron</strong></p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a>Architecture:
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    x₁ ──(w₁)──┐
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>               ├── Σ + b ── ŷ
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    x₂ ──(w₂)──┘
</span></code></pre></div>
<h3 id="code-demonstration">Code Demonstration<a class="headerlink" href="#code-demonstration" title="Permanent link">&para;</a></h3>
<div class="language-python highlight"><pre><span></span><code><span id="__span-1-1"><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
</span><span id="__span-1-2"><a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a><span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
</span><span id="__span-1-3"><a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
</span><span id="__span-1-4"><a id="__codelineno-1-4" name="__codelineno-1-4" href="#__codelineno-1-4"></a><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.linear_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">LinearRegression</span>
</span><span id="__span-1-5"><a id="__codelineno-1-5" name="__codelineno-1-5" href="#__codelineno-1-5"></a>
</span><span id="__span-1-6"><a id="__codelineno-1-6" name="__codelineno-1-6" href="#__codelineno-1-6"></a><span class="c1"># Generate synthetic data: y = 2*x1 + 3*x2 + 1 + noise</span>
</span><span id="__span-1-7"><a id="__codelineno-1-7" name="__codelineno-1-7" href="#__codelineno-1-7"></a><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
</span><span id="__span-1-8"><a id="__codelineno-1-8" name="__codelineno-1-8" href="#__codelineno-1-8"></a><span class="n">n_samples</span> <span class="o">=</span> <span class="mi">1000</span>
</span><span id="__span-1-9"><a id="__codelineno-1-9" name="__codelineno-1-9" href="#__codelineno-1-9"></a><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span><span id="__span-1-10"><a id="__codelineno-1-10" name="__codelineno-1-10" href="#__codelineno-1-10"></a><span class="n">y_true</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span>
</span><span id="__span-1-11"><a id="__codelineno-1-11" name="__codelineno-1-11" href="#__codelineno-1-11"></a><span class="n">y</span> <span class="o">=</span> <span class="n">y_true</span> <span class="o">+</span> <span class="mf">0.1</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span><span id="__span-1-12"><a id="__codelineno-1-12" name="__codelineno-1-12" href="#__codelineno-1-12"></a>
</span><span id="__span-1-13"><a id="__codelineno-1-13" name="__codelineno-1-13" href="#__codelineno-1-13"></a><span class="c1"># SKLEARN LINEAR REGRESSION</span>
</span><span id="__span-1-14"><a id="__codelineno-1-14" name="__codelineno-1-14" href="#__codelineno-1-14"></a><span class="n">sklearn_model</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
</span><span id="__span-1-15"><a id="__codelineno-1-15" name="__codelineno-1-15" href="#__codelineno-1-15"></a><span class="n">sklearn_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</span><span id="__span-1-16"><a id="__codelineno-1-16" name="__codelineno-1-16" href="#__codelineno-1-16"></a><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sklearn: Coefficients=</span><span class="si">{</span><span class="n">sklearn_model</span><span class="o">.</span><span class="n">coef_</span><span class="si">}</span><span class="s2">, Intercept=</span><span class="si">{</span><span class="n">sklearn_model</span><span class="o">.</span><span class="n">intercept_</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="__span-1-17"><a id="__codelineno-1-17" name="__codelineno-1-17" href="#__codelineno-1-17"></a><span class="c1"># Output: Coefficients=[1.997, 2.998], Intercept=1.003</span>
</span><span id="__span-1-18"><a id="__codelineno-1-18" name="__codelineno-1-18" href="#__codelineno-1-18"></a>
</span><span id="__span-1-19"><a id="__codelineno-1-19" name="__codelineno-1-19" href="#__codelineno-1-19"></a><span class="c1"># PYTORCH NEURAL NETWORK (equivalent)</span>
</span><span id="__span-1-20"><a id="__codelineno-1-20" name="__codelineno-1-20" href="#__codelineno-1-20"></a><span class="k">class</span><span class="w"> </span><span class="nc">LinearRegressionNN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="__span-1-21"><a id="__codelineno-1-21" name="__codelineno-1-21" href="#__codelineno-1-21"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">):</span>
</span><span id="__span-1-22"><a id="__codelineno-1-22" name="__codelineno-1-22" href="#__codelineno-1-22"></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="__span-1-23"><a id="__codelineno-1-23" name="__codelineno-1-23" href="#__codelineno-1-23"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># Single linear layer</span>
</span><span id="__span-1-24"><a id="__codelineno-1-24" name="__codelineno-1-24" href="#__codelineno-1-24"></a>
</span><span id="__span-1-25"><a id="__codelineno-1-25" name="__codelineno-1-25" href="#__codelineno-1-25"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
</span><span id="__span-1-26"><a id="__codelineno-1-26" name="__codelineno-1-26" href="#__codelineno-1-26"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="__span-1-27"><a id="__codelineno-1-27" name="__codelineno-1-27" href="#__codelineno-1-27"></a>
</span><span id="__span-1-28"><a id="__codelineno-1-28" name="__codelineno-1-28" href="#__codelineno-1-28"></a><span class="n">nn_model</span> <span class="o">=</span> <span class="n">LinearRegressionNN</span><span class="p">(</span><span class="n">input_dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</span><span id="__span-1-29"><a id="__codelineno-1-29" name="__codelineno-1-29" href="#__codelineno-1-29"></a><span class="c1"># ... training code ...</span>
</span><span id="__span-1-30"><a id="__codelineno-1-30" name="__codelineno-1-30" href="#__codelineno-1-30"></a><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;PyTorch: Weights=</span><span class="si">{</span><span class="n">nn_model</span><span class="o">.</span><span class="n">linear</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="si">}</span><span class="s2">, Bias=</span><span class="si">{</span><span class="n">nn_model</span><span class="o">.</span><span class="n">linear</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="__span-1-31"><a id="__codelineno-1-31" name="__codelineno-1-31" href="#__codelineno-1-31"></a><span class="c1"># Output: Weights=[1.998, 2.999], Bias=1.002</span>
</span></code></pre></div>
<h3 id="key-insight">Key Insight<a class="headerlink" href="#key-insight" title="Permanent link">&para;</a></h3>
<p><strong>Linear regression IS a neural network</strong> with:
- 0 hidden layers
- Linear (identity) activation
- MSE loss</p>
<p>The sklearn <code>LinearRegression</code> uses a closed-form solution (matrix inverse), while the neural network uses gradient descent, but they converge to the same answer.</p>
<p><strong>Why use gradient descent for linear regression?</strong> The closed-form solution requires O(n³) matrix inversion—prohibitive for millions of samples or thousands of features. Stochastic gradient descent scales via mini-batches. Also, closed-form only works for squared error with linear models. Gradient descent handles L1 regularization, non-standard losses, and extends to non-linear models. Use closed-form when small enough; gradient descent otherwise.</p>
<hr />
<h2 id="example-2-logistic-regression">Example 2: Logistic Regression<a class="headerlink" href="#example-2-logistic-regression" title="Permanent link">&para;</a></h2>
<p><strong>Binary classification</strong>: Neural networks can implement logistic regression exactly.</p>
<h3 id="logistic-regression-model">Logistic Regression Model<a class="headerlink" href="#logistic-regression-model" title="Permanent link">&para;</a></h3>
<div class="arithmatex">\[P(y=1|x) = \sigma(w^T x + b) = \frac{1}{1 + e^{-(w^T x + b)}}\]</div>
<h3 id="neural-network-equivalent_1">Neural Network Equivalent<a class="headerlink" href="#neural-network-equivalent_1" title="Permanent link">&para;</a></h3>
<p>A neural network with:
- <strong>No hidden layers</strong>
- <strong>Sigmoid activation</strong> on the output
- <strong>Binary cross-entropy loss</strong></p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-2-1"><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a>Architecture:
</span><span id="__span-2-2"><a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a>    x₁ ──(w₁)──┐
</span><span id="__span-2-3"><a id="__codelineno-2-3" name="__codelineno-2-3" href="#__codelineno-2-3"></a>               ├── Σ + b ── σ ── P(y=1)
</span><span id="__span-2-4"><a id="__codelineno-2-4" name="__codelineno-2-4" href="#__codelineno-2-4"></a>    x₂ ──(w₂)──┘
</span></code></pre></div>
<h3 id="code-demonstration_1">Code Demonstration<a class="headerlink" href="#code-demonstration_1" title="Permanent link">&para;</a></h3>
<div class="language-python highlight"><pre><span></span><code><span id="__span-3-1"><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.linear_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">LogisticRegression</span>
</span><span id="__span-3-2"><a id="__codelineno-3-2" name="__codelineno-3-2" href="#__codelineno-3-2"></a><span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
</span><span id="__span-3-3"><a id="__codelineno-3-3" name="__codelineno-3-3" href="#__codelineno-3-3"></a>
</span><span id="__span-3-4"><a id="__codelineno-3-4" name="__codelineno-3-4" href="#__codelineno-3-4"></a><span class="c1"># SKLEARN LOGISTIC REGRESSION</span>
</span><span id="__span-3-5"><a id="__codelineno-3-5" name="__codelineno-3-5" href="#__codelineno-3-5"></a><span class="n">sklearn_model</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">penalty</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</span><span id="__span-3-6"><a id="__codelineno-3-6" name="__codelineno-3-6" href="#__codelineno-3-6"></a><span class="n">sklearn_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</span><span id="__span-3-7"><a id="__codelineno-3-7" name="__codelineno-3-7" href="#__codelineno-3-7"></a>
</span><span id="__span-3-8"><a id="__codelineno-3-8" name="__codelineno-3-8" href="#__codelineno-3-8"></a><span class="c1"># PYTORCH NEURAL NETWORK (equivalent)</span>
</span><span id="__span-3-9"><a id="__codelineno-3-9" name="__codelineno-3-9" href="#__codelineno-3-9"></a><span class="k">class</span><span class="w"> </span><span class="nc">LogisticRegressionNN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="__span-3-10"><a id="__codelineno-3-10" name="__codelineno-3-10" href="#__codelineno-3-10"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">):</span>
</span><span id="__span-3-11"><a id="__codelineno-3-11" name="__codelineno-3-11" href="#__codelineno-3-11"></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="__span-3-12"><a id="__codelineno-3-12" name="__codelineno-3-12" href="#__codelineno-3-12"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="__span-3-13"><a id="__codelineno-3-13" name="__codelineno-3-13" href="#__codelineno-3-13"></a>
</span><span id="__span-3-14"><a id="__codelineno-3-14" name="__codelineno-3-14" href="#__codelineno-3-14"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
</span><span id="__span-3-15"><a id="__codelineno-3-15" name="__codelineno-3-15" href="#__codelineno-3-15"></a>        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</span><span id="__span-3-16"><a id="__codelineno-3-16" name="__codelineno-3-16" href="#__codelineno-3-16"></a>
</span><span id="__span-3-17"><a id="__codelineno-3-17" name="__codelineno-3-17" href="#__codelineno-3-17"></a><span class="c1"># Both produce the same decision boundary!</span>
</span></code></pre></div>
<h3 id="key-insight_1">Key Insight<a class="headerlink" href="#key-insight_1" title="Permanent link">&para;</a></h3>
<p><strong>Logistic regression IS a neural network</strong> with:
- 0 hidden layers
- Sigmoid activation
- Binary cross-entropy loss</p>
<p>The decision boundary is identical: a linear hyperplane.</p>
<hr />
<h2 id="example-3-approximating-step-functions">Example 3: Approximating Step Functions<a class="headerlink" href="#example-3-approximating-step-functions" title="Permanent link">&para;</a></h2>
<p><strong>The challenge</strong>: Decision trees create axis-aligned step functions. Can neural networks do this?</p>
<h3 id="decision-tree-behavior">Decision Tree Behavior<a class="headerlink" href="#decision-tree-behavior" title="Permanent link">&para;</a></h3>
<div class="language-text highlight"><pre><span></span><code><span id="__span-4-1"><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a>Decision tree output:
</span><span id="__span-4-2"><a id="__codelineno-4-2" name="__codelineno-4-2" href="#__codelineno-4-2"></a>     1 ┌───────────┐
</span><span id="__span-4-3"><a id="__codelineno-4-3" name="__codelineno-4-3" href="#__codelineno-4-3"></a>       │           │
</span><span id="__span-4-4"><a id="__codelineno-4-4" name="__codelineno-4-4" href="#__codelineno-4-4"></a>       │           │
</span><span id="__span-4-5"><a id="__codelineno-4-5" name="__codelineno-4-5" href="#__codelineno-4-5"></a>     0 ┘           └───────────
</span><span id="__span-4-6"><a id="__codelineno-4-6" name="__codelineno-4-6" href="#__codelineno-4-6"></a>              x = 0.5
</span><span id="__span-4-7"><a id="__codelineno-4-7" name="__codelineno-4-7" href="#__codelineno-4-7"></a>       (hard step at threshold)
</span></code></pre></div>
<h3 id="neural-network-approximation">Neural Network Approximation<a class="headerlink" href="#neural-network-approximation" title="Permanent link">&para;</a></h3>
<p>A ReLU neuron creates a "bent line":
$<span class="arithmatex">\(\text{ReLU}(x) = \max(0, x)\)</span>$</p>
<p><img alt="ReLU Function" src="../../assets/deep_dive/relu_function.png" /></p>
<p>Combining ReLUs can approximate steps:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-5-1"><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a><span class="k">def</span><span class="w"> </span><span class="nf">train_step_approximator</span><span class="p">(</span><span class="n">n_hidden</span><span class="p">):</span>
</span><span id="__span-5-2"><a id="__codelineno-5-2" name="__codelineno-5-2" href="#__codelineno-5-2"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Train a network to approximate a step function.&quot;&quot;&quot;</span>
</span><span id="__span-5-3"><a id="__codelineno-5-3" name="__codelineno-5-3" href="#__codelineno-5-3"></a>    <span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
</span><span id="__span-5-4"><a id="__codelineno-5-4" name="__codelineno-5-4" href="#__codelineno-5-4"></a>        <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_hidden</span><span class="p">),</span>
</span><span id="__span-5-5"><a id="__codelineno-5-5" name="__codelineno-5-5" href="#__codelineno-5-5"></a>        <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
</span><span id="__span-5-6"><a id="__codelineno-5-6" name="__codelineno-5-6" href="#__codelineno-5-6"></a>        <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_hidden</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
</span><span id="__span-5-7"><a id="__codelineno-5-7" name="__codelineno-5-7" href="#__codelineno-5-7"></a>        <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>
</span><span id="__span-5-8"><a id="__codelineno-5-8" name="__codelineno-5-8" href="#__codelineno-5-8"></a>    <span class="p">)</span>
</span><span id="__span-5-9"><a id="__codelineno-5-9" name="__codelineno-5-9" href="#__codelineno-5-9"></a>    <span class="c1"># ... training code ...</span>
</span><span id="__span-5-10"><a id="__codelineno-5-10" name="__codelineno-5-10" href="#__codelineno-5-10"></a>    <span class="k">return</span> <span class="n">model</span>
</span><span id="__span-5-11"><a id="__codelineno-5-11" name="__codelineno-5-11" href="#__codelineno-5-11"></a>
</span><span id="__span-5-12"><a id="__codelineno-5-12" name="__codelineno-5-12" href="#__codelineno-5-12"></a><span class="c1"># Results:</span>
</span><span id="__span-5-13"><a id="__codelineno-5-13" name="__codelineno-5-13" href="#__codelineno-5-13"></a><span class="c1"># 2 neurons: rough approximation</span>
</span><span id="__span-5-14"><a id="__codelineno-5-14" name="__codelineno-5-14" href="#__codelineno-5-14"></a><span class="c1"># 5 neurons: better</span>
</span><span id="__span-5-15"><a id="__codelineno-5-15" name="__codelineno-5-15" href="#__codelineno-5-15"></a><span class="c1"># 50 neurons: nearly exact step</span>
</span></code></pre></div>
<p><strong>Observation</strong>: More neurons → sharper approximation of the step.</p>
<h3 id="why-relu-combinations-work">Why ReLU Combinations Work<a class="headerlink" href="#why-relu-combinations-work" title="Permanent link">&para;</a></h3>
<p>A single ReLU is a ramp: <span class="arithmatex">\(\max(0, x)\)</span></p>
<p>Two ReLUs can make a bump:
$<span class="arithmatex">\(f(x) = \text{ReLU}(x) - \text{ReLU}(x - 1)\)</span>$</p>
<p><img alt="ReLU Bump" src="../../assets/deep_dive/relu_bump.png" /></p>
<p>Many bumps at different positions → approximate any shape.</p>
<h3 id="key-insight_2">Key Insight<a class="headerlink" href="#key-insight_2" title="Permanent link">&para;</a></h3>
<p>Neural networks can <strong>approximate</strong> decision tree boundaries, but:
- Trees create <strong>exact</strong> axis-aligned steps
- NNs create <strong>smooth</strong> approximations that approach steps
- With enough neurons, the approximation becomes arbitrarily close</p>
<hr />
<h2 id="example-4-polynomial-regression">Example 4: Polynomial Regression<a class="headerlink" href="#example-4-polynomial-regression" title="Permanent link">&para;</a></h2>
<p><strong>Challenge</strong>: Learn <span class="arithmatex">\(y = x^2\)</span> using only linear layers and ReLU.</p>
<h3 id="the-problem">The Problem<a class="headerlink" href="#the-problem" title="Permanent link">&para;</a></h3>
<p>A single linear layer can only learn: <span class="arithmatex">\(y = wx + b\)</span></p>
<p>How can we learn <span class="arithmatex">\(y = x^2\)</span> without explicitly computing <span class="arithmatex">\(x^2\)</span>?</p>
<h3 id="the-solution-hidden-layer-creates-basis-functions">The Solution: Hidden Layer Creates Basis Functions<a class="headerlink" href="#the-solution-hidden-layer-creates-basis-functions" title="Permanent link">&para;</a></h3>
<p>With ReLU activations, the network learns piecewise linear approximations:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-6-1"><a id="__codelineno-6-1" name="__codelineno-6-1" href="#__codelineno-6-1"></a><span class="c1"># Train networks with different widths to learn y = x²</span>
</span><span id="__span-6-2"><a id="__codelineno-6-2" name="__codelineno-6-2" href="#__codelineno-6-2"></a><span class="c1"># Results:</span>
</span><span id="__span-6-3"><a id="__codelineno-6-3" name="__codelineno-6-3" href="#__codelineno-6-3"></a><span class="c1"># 2 neurons: Very rough (2 line segments)</span>
</span><span id="__span-6-4"><a id="__codelineno-6-4" name="__codelineno-6-4" href="#__codelineno-6-4"></a><span class="c1"># 5 neurons: Better (5 segments)</span>
</span><span id="__span-6-5"><a id="__codelineno-6-5" name="__codelineno-6-5" href="#__codelineno-6-5"></a><span class="c1"># 50 neurons: Nearly perfect curve</span>
</span><span id="__span-6-6"><a id="__codelineno-6-6" name="__codelineno-6-6" href="#__codelineno-6-6"></a><span class="c1"># 100 neurons: Indistinguishable from x²</span>
</span></code></pre></div>
<h3 id="whats-happening-inside">What's Happening Inside<a class="headerlink" href="#whats-happening-inside" title="Permanent link">&para;</a></h3>
<p>Each ReLU neuron contributes a "kink" in the function:</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-7-1"><a id="__codelineno-7-1" name="__codelineno-7-1" href="#__codelineno-7-1"></a>Hidden neuron 1: ReLU(w₁x + b₁) - kink at x = -b₁/w₁
</span><span id="__span-7-2"><a id="__codelineno-7-2" name="__codelineno-7-2" href="#__codelineno-7-2"></a>Hidden neuron 2: ReLU(w₂x + b₂) - kink at x = -b₂/w₂
</span><span id="__span-7-3"><a id="__codelineno-7-3" name="__codelineno-7-3" href="#__codelineno-7-3"></a>...
</span><span id="__span-7-4"><a id="__codelineno-7-4" name="__codelineno-7-4" href="#__codelineno-7-4"></a>
</span><span id="__span-7-5"><a id="__codelineno-7-5" name="__codelineno-7-5" href="#__codelineno-7-5"></a>Output = sum of scaled, shifted kinks = piecewise linear approximation
</span></code></pre></div>
<p>The network learns WHERE to put kinks and HOW MUCH each contributes.</p>
<h3 id="key-insight_3">Key Insight<a class="headerlink" href="#key-insight_3" title="Permanent link">&para;</a></h3>
<p>Neural networks don't explicitly compute polynomials—they approximate them with <strong>piecewise linear functions</strong>. More neurons = more pieces = smoother approximation.</p>
<hr />
<h2 id="the-unifying-framework">The Unifying Framework<a class="headerlink" href="#the-unifying-framework" title="Permanent link">&para;</a></h2>
<p>All these models are points on a spectrum:</p>
<p><img alt="Model Complexity Spectrum" src="../../assets/deep_dive/model_spectrum.png" /></p>
<h3 id="flexibility-trade-offs">Flexibility Trade-offs<a class="headerlink" href="#flexibility-trade-offs" title="Permanent link">&para;</a></h3>
<table>
<thead>
<tr>
<th>Model</th>
<th>Flexibility</th>
<th>Data Needed</th>
<th>Interpretability</th>
<th>Overfitting Risk</th>
</tr>
</thead>
<tbody>
<tr>
<td>Linear Regression</td>
<td>Low</td>
<td>Low</td>
<td>High</td>
<td>Low</td>
</tr>
<tr>
<td>Logistic Regression</td>
<td>Low</td>
<td>Low</td>
<td>High</td>
<td>Low</td>
</tr>
<tr>
<td>Decision Tree</td>
<td>Medium</td>
<td>Medium</td>
<td>High</td>
<td>Medium</td>
</tr>
<tr>
<td>Shallow NN</td>
<td>High</td>
<td>Medium</td>
<td>Low</td>
<td>Medium</td>
</tr>
<tr>
<td>Deep NN</td>
<td>Very High</td>
<td>High</td>
<td>Very Low</td>
<td>High</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="when-to-use-simpler-models">When to Use Simpler Models<a class="headerlink" href="#when-to-use-simpler-models" title="Permanent link">&para;</a></h2>
<p>Even though NNs can do everything, simpler models are often better:</p>
<ol>
<li><strong>Interpretability required</strong>: Linear/logistic regression coefficients are meaningful</li>
<li><strong>Small data</strong>: Simple models generalize better with few samples</li>
<li><strong>Fast inference</strong>: Linear prediction is O(d), deep NN is O(millions)</li>
<li><strong>Debugging</strong>: Easier to understand what went wrong</li>
<li><strong>Baseline</strong>: Always try simple models first</li>
</ol>
<h3 id="example-decision">Example Decision<a class="headerlink" href="#example-decision" title="Permanent link">&para;</a></h3>
<p><strong>You have 100 samples and want to predict a continuous outcome. Neural network or linear regression?</strong></p>
<p>Start with linear regression. With 100 samples, a neural network will likely overfit unless heavily regularized. Linear regression provides a strong baseline and is interpretable.</p>
<p><strong>Samples per parameter</strong>: Traditional rules (10-20 samples per parameter) don't apply cleanly to neural networks. Modern NNs often work in the overparameterized regime (more parameters than samples) due to implicit regularization from SGD, early stopping, and batch normalization. The honest answer: monitor validation loss. If it diverges from training loss, you're overfitting—apply more regularization, get more data, or use a smaller model.</p>
<hr />
<h2 id="when-neural-networks-shine">When Neural Networks Shine<a class="headerlink" href="#when-neural-networks-shine" title="Permanent link">&para;</a></h2>
<ol>
<li><strong>Large data</strong>: More samples → can fit more complex patterns</li>
<li><strong>Raw inputs</strong>: Images, audio, text need feature learning</li>
<li><strong>Complex relationships</strong>: Highly non-linear, interacting features</li>
<li><strong>Transfer learning</strong>: Pre-trained models for your task</li>
</ol>
<h3 id="example-decision_1">Example Decision<a class="headerlink" href="#example-decision_1" title="Permanent link">&para;</a></h3>
<p><strong>You have 1 million images and want to classify them. Neural network or logistic regression?</strong></p>
<p>Neural network, specifically a CNN. Logistic regression would require hand-engineered features and couldn't capture the spatial patterns that CNNs learn automatically.</p>
<hr />
<h2 id="common-misconceptions">Common Misconceptions<a class="headerlink" href="#common-misconceptions" title="Permanent link">&para;</a></h2>
<table>
<thead>
<tr>
<th>Misconception</th>
<th>Reality</th>
</tr>
</thead>
<tbody>
<tr>
<td>"Neural networks understand data better than simpler models"</td>
<td>NNs fit patterns statistically; simpler models may capture the <em>true</em> underlying structure better</td>
</tr>
<tr>
<td>"Universal approximation means NNs are always best"</td>
<td>The theorem says nothing about training difficulty, data requirements, or generalization</td>
</tr>
<tr>
<td>"More neurons is always better"</td>
<td>More neurons = more capacity to overfit; regularization and data size matter</td>
</tr>
<tr>
<td>"Deep networks are always better than shallow"</td>
<td>For some functions, shallow networks are more efficient; depth helps for compositional structure</td>
</tr>
<tr>
<td>"If sklearn and PyTorch give same results, there's no benefit to NNs"</td>
<td>True for simple models, but NNs allow extending to more complex architectures</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="reflection-questions">Reflection Questions<a class="headerlink" href="#reflection-questions" title="Permanent link">&para;</a></h2>
<ol>
<li>
<p>If neural networks can approximate any function, why use simpler models?</p>
</li>
<li>
<p>What does a neural network learn that logistic regression doesn't?</p>
</li>
<li>
<p>How many hidden neurons are needed to approximate a degree-n polynomial?</p>
</li>
<li>
<p>The Universal Approximation Theorem says one hidden layer is enough. Why do we use deep networks?</p>
</li>
<li>
<p>Your neural network achieves 100% training accuracy but 60% test accuracy. What happened?</p>
</li>
<li>
<p>A colleague says "just use a deep neural network for everything." What's your response?</p>
</li>
</ol>
<hr />
<h2 id="practice-problems">Practice Problems<a class="headerlink" href="#practice-problems" title="Permanent link">&para;</a></h2>
<ol>
<li>
<p>Train a neural network to learn <span class="arithmatex">\(\sin(x)\)</span> - how many neurons needed for MSE &lt; 0.01?</p>
</li>
<li>
<p>Implement logistic regression as a neural network and verify it matches sklearn</p>
</li>
<li>
<p>Find the minimum network (fewest neurons) that achieves 95% accuracy on XOR</p>
</li>
<li>
<p>Compare training time: sklearn vs PyTorch for logistic regression on a large dataset</p>
</li>
</ol>
<hr />
<h2 id="summary">Summary<a class="headerlink" href="#summary" title="Permanent link">&para;</a></h2>
<p><strong>Key takeaways:</strong></p>
<ol>
<li>
<p>The <strong>Universal Approximation Theorem</strong> guarantees that neural networks can learn any reasonable function (given enough neurons)</p>
</li>
<li>
<p><strong>Linear regression</strong> is a neural network with 0 hidden layers and no activation</p>
</li>
<li>
<p><strong>Logistic regression</strong> is a neural network with 0 hidden layers and sigmoid activation</p>
</li>
<li>
<p>Neural networks approximate step functions and polynomials through <strong>piecewise linear combinations</strong> of ReLU units</p>
</li>
<li>
<p>The theorem guarantees <strong>existence</strong> but says nothing about <strong>training difficulty</strong>, <strong>data requirements</strong>, or <strong>generalization</strong></p>
</li>
<li>
<p><strong>Simpler models are often better</strong>: interpretability, fewer data requirements, faster training, less overfitting</p>
</li>
<li>
<p><strong>Match model complexity to problem complexity and data size</strong></p>
</li>
</ol>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "../..", "features": ["navigation.instant", "navigation.tracking", "navigation.sections", "navigation.expand", "navigation.top", "search.suggest", "search.highlight", "content.code.copy"], "search": "../../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.79ae519e.min.js"></script>
      
        <script src="../../javascripts/mathjax.js"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>