
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Predictive Modeling - Course Companion">
      
      
        <meta name="author" content="Nick Freeman">
      
      
        <link rel="canonical" href="https://nkfreeman-teaching.github.io/BAN-501-course-companion/modules/07-computer-vision/">
      
      
        <link rel="prev" href="../06-neural-networks/">
      
      
        <link rel="next" href="../08-nlp/">
      
      
        
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.1">
    
    
      
        <title>7. Computer Vision - BAN 501 Course Companion</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.484c7ddc.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.ab4e12ef.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#module-7-computer-vision-cnns" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="BAN 501 Course Companion" class="md-header__button md-logo" aria-label="BAN 501 Course Companion" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            BAN 501 Course Companion
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              7. Computer Vision
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/nkfreeman-teaching/BAN-501-course-companion" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    nkfreeman-teaching/BAN-501-course-companion
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="BAN 501 Course Companion" class="md-nav__button md-logo" aria-label="BAN 501 Course Companion" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    BAN 501 Course Companion
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/nkfreeman-teaching/BAN-501-course-companion" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    nkfreeman-teaching/BAN-501-course-companion
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Home
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    Modules
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    Modules
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../01-foundations/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    1. Foundations of ML
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../02-regression/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    2. Regression
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../03-classification/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    3. Classification
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../04-ensemble-methods/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    4. Ensemble Methods
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../05-unsupervised/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    5. Unsupervised Learning
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../06-neural-networks/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    6. Neural Networks
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    
  
    7. Computer Vision
  

    
  </span>
  
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    
  
    7. Computer Vision
  

    
  </span>
  
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#introduction" class="md-nav__link">
    <span class="md-ellipsis">
      
        Introduction
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#learning-objectives" class="md-nav__link">
    <span class="md-ellipsis">
      
        Learning Objectives
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#71-working-with-images" class="md-nav__link">
    <span class="md-ellipsis">
      
        7.1 Working with Images
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="7.1 Working with Images">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#how-images-are-represented" class="md-nav__link">
    <span class="md-ellipsis">
      
        How Images Are Represented
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#imagenet-the-benchmark-that-changed-everything" class="md-nav__link">
    <span class="md-ellipsis">
      
        ImageNet: The Benchmark That Changed Everything
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#why-fully-connected-networks-fail" class="md-nav__link">
    <span class="md-ellipsis">
      
        Why Fully Connected Networks Fail
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#72-convolutional-neural-networks" class="md-nav__link">
    <span class="md-ellipsis">
      
        7.2 Convolutional Neural Networks
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="7.2 Convolutional Neural Networks">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-convolution-operation" class="md-nav__link">
    <span class="md-ellipsis">
      
        The Convolution Operation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#multi-channel-convolution" class="md-nav__link">
    <span class="md-ellipsis">
      
        Multi-Channel Convolution
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#what-filters-learn" class="md-nav__link">
    <span class="md-ellipsis">
      
        What Filters Learn
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pooling-layers" class="md-nav__link">
    <span class="md-ellipsis">
      
        Pooling Layers
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#classic-cnn-pattern" class="md-nav__link">
    <span class="md-ellipsis">
      
        Classic CNN Pattern
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parameter-efficiency" class="md-nav__link">
    <span class="md-ellipsis">
      
        Parameter Efficiency
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#historical-architectures" class="md-nav__link">
    <span class="md-ellipsis">
      
        Historical Architectures
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#skip-residual-connections" class="md-nav__link">
    <span class="md-ellipsis">
      
        Skip (Residual) Connections
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#common-misconceptions" class="md-nav__link">
    <span class="md-ellipsis">
      
        Common Misconceptions
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#73-transfer-learning" class="md-nav__link">
    <span class="md-ellipsis">
      
        7.3 Transfer Learning
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="7.3 Transfer Learning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-core-idea" class="md-nav__link">
    <span class="md-ellipsis">
      
        The Core Idea
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#feature-extraction" class="md-nav__link">
    <span class="md-ellipsis">
      
        Feature Extraction
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fine-tuning" class="md-nav__link">
    <span class="md-ellipsis">
      
        Fine-Tuning
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#when-to-use-which" class="md-nav__link">
    <span class="md-ellipsis">
      
        When to Use Which
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#business-value-of-transfer-learning" class="md-nav__link">
    <span class="md-ellipsis">
      
        Business Value of Transfer Learning
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#74-modern-vision-applications" class="md-nav__link">
    <span class="md-ellipsis">
      
        7.4 Modern Vision Applications
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="7.4 Modern Vision Applications">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#object-detection" class="md-nav__link">
    <span class="md-ellipsis">
      
        Object Detection
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#image-segmentation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Image Segmentation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vision-transformers-vit" class="md-nav__link">
    <span class="md-ellipsis">
      
        Vision Transformers (ViT)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#business-applications" class="md-nav__link">
    <span class="md-ellipsis">
      
        Business Applications
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#reflection-questions" class="md-nav__link">
    <span class="md-ellipsis">
      
        Reflection Questions
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#practice-problems" class="md-nav__link">
    <span class="md-ellipsis">
      
        Practice Problems
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#chapter-summary" class="md-nav__link">
    <span class="md-ellipsis">
      
        Chapter Summary
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#whats-next" class="md-nav__link">
    <span class="md-ellipsis">
      
        What's Next
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../08-nlp/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    8. NLP
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../09-interpretability/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    9. Interpretability
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../10-ethics-deployment/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    10. Ethics & Deployment
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    Appendices
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    Appendices
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../appendices/universal-approximators/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Neural Networks as Universal Approximators
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../appendices/cnn-architecture/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    CNN Architecture
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../appendices/transformer-architecture/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Transformer Architecture
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#introduction" class="md-nav__link">
    <span class="md-ellipsis">
      
        Introduction
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#learning-objectives" class="md-nav__link">
    <span class="md-ellipsis">
      
        Learning Objectives
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#71-working-with-images" class="md-nav__link">
    <span class="md-ellipsis">
      
        7.1 Working with Images
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="7.1 Working with Images">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#how-images-are-represented" class="md-nav__link">
    <span class="md-ellipsis">
      
        How Images Are Represented
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#imagenet-the-benchmark-that-changed-everything" class="md-nav__link">
    <span class="md-ellipsis">
      
        ImageNet: The Benchmark That Changed Everything
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#why-fully-connected-networks-fail" class="md-nav__link">
    <span class="md-ellipsis">
      
        Why Fully Connected Networks Fail
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#72-convolutional-neural-networks" class="md-nav__link">
    <span class="md-ellipsis">
      
        7.2 Convolutional Neural Networks
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="7.2 Convolutional Neural Networks">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-convolution-operation" class="md-nav__link">
    <span class="md-ellipsis">
      
        The Convolution Operation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#multi-channel-convolution" class="md-nav__link">
    <span class="md-ellipsis">
      
        Multi-Channel Convolution
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#what-filters-learn" class="md-nav__link">
    <span class="md-ellipsis">
      
        What Filters Learn
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pooling-layers" class="md-nav__link">
    <span class="md-ellipsis">
      
        Pooling Layers
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#classic-cnn-pattern" class="md-nav__link">
    <span class="md-ellipsis">
      
        Classic CNN Pattern
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parameter-efficiency" class="md-nav__link">
    <span class="md-ellipsis">
      
        Parameter Efficiency
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#historical-architectures" class="md-nav__link">
    <span class="md-ellipsis">
      
        Historical Architectures
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#skip-residual-connections" class="md-nav__link">
    <span class="md-ellipsis">
      
        Skip (Residual) Connections
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#common-misconceptions" class="md-nav__link">
    <span class="md-ellipsis">
      
        Common Misconceptions
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#73-transfer-learning" class="md-nav__link">
    <span class="md-ellipsis">
      
        7.3 Transfer Learning
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="7.3 Transfer Learning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-core-idea" class="md-nav__link">
    <span class="md-ellipsis">
      
        The Core Idea
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#feature-extraction" class="md-nav__link">
    <span class="md-ellipsis">
      
        Feature Extraction
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fine-tuning" class="md-nav__link">
    <span class="md-ellipsis">
      
        Fine-Tuning
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#when-to-use-which" class="md-nav__link">
    <span class="md-ellipsis">
      
        When to Use Which
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#business-value-of-transfer-learning" class="md-nav__link">
    <span class="md-ellipsis">
      
        Business Value of Transfer Learning
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#74-modern-vision-applications" class="md-nav__link">
    <span class="md-ellipsis">
      
        7.4 Modern Vision Applications
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="7.4 Modern Vision Applications">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#object-detection" class="md-nav__link">
    <span class="md-ellipsis">
      
        Object Detection
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#image-segmentation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Image Segmentation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vision-transformers-vit" class="md-nav__link">
    <span class="md-ellipsis">
      
        Vision Transformers (ViT)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#business-applications" class="md-nav__link">
    <span class="md-ellipsis">
      
        Business Applications
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#reflection-questions" class="md-nav__link">
    <span class="md-ellipsis">
      
        Reflection Questions
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#practice-problems" class="md-nav__link">
    <span class="md-ellipsis">
      
        Practice Problems
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#chapter-summary" class="md-nav__link">
    <span class="md-ellipsis">
      
        Chapter Summary
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#whats-next" class="md-nav__link">
    <span class="md-ellipsis">
      
        What's Next
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              
              <article class="md-content__inner md-typeset">
                
                  


  
  


<h1 id="module-7-computer-vision-cnns">Module 7: Computer Vision &amp; CNNs<a class="headerlink" href="#module-7-computer-vision-cnns" title="Permanent link">&para;</a></h1>
<h2 id="introduction">Introduction<a class="headerlink" href="#introduction" title="Permanent link">&para;</a></h2>
<p>Last module we learned neural network fundamentals—layers, activations, backpropagation, PyTorch. Today we specialize those concepts for images.</p>
<p>Images are everywhere in business: quality control in manufacturing, inventory management in retail, medical imaging in healthcare, document processing in finance. Computer vision has transformed all of these industries.</p>
<p>But images present unique challenges. A single photo is millions of numbers. Fully connected networks can't scale. And we need spatial awareness—a cat in the corner is still a cat, but its pixels are in completely different positions.</p>
<p>Convolutional Neural Networks solve these problems. By the end of today, you'll understand how CNNs work, and critically, you'll know how to leverage <strong>transfer learning</strong> so you don't have to train from scratch.</p>
<p><strong>Transfer learning works broadly</strong>: Early CNN layers learn universal visual primitives (edges, textures) that transfer to any domain. Studies show ImageNet transfer helps on X-rays, satellite images, even art classification. Train from scratch only with massive domain data AND truly different image statistics—even then, ImageNet weights as initialization usually help.</p>
<hr />
<h2 id="learning-objectives">Learning Objectives<a class="headerlink" href="#learning-objectives" title="Permanent link">&para;</a></h2>
<p>By the end of this module, you should be able to:</p>
<ol>
<li><strong>Explain</strong> how images are represented as data (matrices, channels)</li>
<li><strong>Describe</strong> why fully connected networks are inefficient for images</li>
<li><strong>Explain</strong> the mechanics of convolutional layers and pooling</li>
<li><strong>Implement</strong> a CNN in PyTorch for image classification</li>
<li><strong>Apply</strong> transfer learning using pre-trained models</li>
<li><strong>Understand</strong> modern CV applications (detection, segmentation, ViT)</li>
</ol>
<hr />
<h2 id="71-working-with-images">7.1 Working with Images<a class="headerlink" href="#71-working-with-images" title="Permanent link">&para;</a></h2>
<h3 id="how-images-are-represented">How Images Are Represented<a class="headerlink" href="#how-images-are-represented" title="Permanent link">&para;</a></h3>
<p>Digital images are matrices of numbers.</p>
<p><strong>Grayscale</strong>: 2D matrix (Height × Width). Each pixel is an intensity from 0 (black) to 255 (white).</p>
<p><strong>Color (RGB)</strong>: 3D tensor (Height × Width × 3). Three channels—Red, Green, Blue—each with its own intensity matrix.</p>
<p><strong>Example</strong>: A 224×224 color image
- Shape: (224, 224, 3)
- Total values: 224 × 224 × 3 = <strong>150,528 numbers</strong></p>
<p><strong>PyTorch convention</strong>: (Batch, Channels, Height, Width)—NCHW format.</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">PIL</span><span class="w"> </span><span class="kn">import</span> <span class="n">Image</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a><span class="n">img</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s1">&#39;photo.jpg&#39;</span><span class="p">)</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a><span class="n">img_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Shape: </span><span class="si">{</span><span class="n">img_array</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># (Height, Width, Channels)</span>
</span></code></pre></div>
<h3 id="imagenet-the-benchmark-that-changed-everything">ImageNet: The Benchmark That Changed Everything<a class="headerlink" href="#imagenet-the-benchmark-that-changed-everything" title="Permanent link">&para;</a></h3>
<table>
<thead>
<tr>
<th>Year</th>
<th>Winner</th>
<th>Top-5 Error</th>
<th>Significance</th>
</tr>
</thead>
<tbody>
<tr>
<td>2010</td>
<td>Traditional</td>
<td>28.2%</td>
<td>Pre-deep learning</td>
</tr>
<tr>
<td>2012</td>
<td>AlexNet</td>
<td>16.4%</td>
<td>CNN breakthrough</td>
</tr>
<tr>
<td>2015</td>
<td>ResNet</td>
<td>3.6%</td>
<td>Beat humans (~5%)</td>
</tr>
</tbody>
</table>
<p>In 2012, AlexNet—a convolutional neural network—crushed the competition. Error dropped from 28% to 16%. That's not incremental improvement; that's a paradigm shift.</p>
<p>By 2015, ResNet beat human performance on ImageNet classification.</p>
<h3 id="why-fully-connected-networks-fail">Why Fully Connected Networks Fail<a class="headerlink" href="#why-fully-connected-networks-fail" title="Permanent link">&para;</a></h3>
<p><strong>Problem 1: Too many parameters</strong>
- 224×224×3 input with 1000 hidden neurons
- = 150 million parameters in first layer alone!
- Impossible to train, will overfit immediately</p>
<p><strong>Problem 2: No spatial understanding</strong>
- Fully connected layers treat each pixel independently
- A cat in the corner has completely different pixel positions than a cat in the center
- The network can't generalize</p>
<p><strong>The solution</strong>: Convolutional Neural Networks</p>
<p><strong>Why position matters</strong>: A fully connected network treats each pixel independently—"pixel 1,000 is orange" vs. "pixel 50,000 is orange" are completely different inputs. To recognize cats anywhere, it would need examples at every possible position (billions of configurations). CNNs solve this with weight sharing: the same filter scans all positions, so learning to detect a cat's eye at one position automatically applies everywhere.</p>
<hr />
<h2 id="72-convolutional-neural-networks">7.2 Convolutional Neural Networks<a class="headerlink" href="#72-convolutional-neural-networks" title="Permanent link">&para;</a></h2>
<h3 id="the-convolution-operation">The Convolution Operation<a class="headerlink" href="#the-convolution-operation" title="Permanent link">&para;</a></h3>
<p>Instead of connecting every input to every output, we slide a small filter across the image.</p>
<p><strong>The operation:</strong>
1. Take a small filter (e.g., 3×3)
2. Slide it across the image
3. At each position, compute dot product of filter and patch
4. Output is a "feature map"</p>
<p><strong>Key parameters:</strong>
- <strong>Filter size</strong>: 3×3 or 5×5 typical
- <strong>Stride</strong>: How many pixels to move (1 or 2)
- <strong>Padding</strong>: Zeros around edges to control output size
- <strong>Number of filters</strong>: Each learns a different feature</p>
<h3 id="multi-channel-convolution">Multi-Channel Convolution<a class="headerlink" href="#multi-channel-convolution" title="Permanent link">&para;</a></h3>
<p><strong>Key insight: A "3×3 filter" on an RGB image is actually a 3×3×3 tensor.</strong></p>
<p>When we say "3×3 filter," we're describing the spatial dimensions. But the filter must match the depth of the input.</p>
<p>For an RGB image with 3 channels:
- Filter shape: 3 × 3 × 3 = <strong>27 weights</strong> (plus 1 bias)
- Each channel (R, G, B) has its own 3×3 slice</p>
<p><strong>How the computation works:</strong></p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-1-1"><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a>At each spatial position:
</span><span id="__span-1-2"><a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a>1. Extract the 3×3×3 patch from the input
</span><span id="__span-1-3"><a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a>2. Multiply element-wise with the 3×3×3 filter (27 multiplications)
</span><span id="__span-1-4"><a id="__codelineno-1-4" name="__codelineno-1-4" href="#__codelineno-1-4"></a>3. Sum ALL 27 products + bias → ONE output value
</span></code></pre></div>
<p><strong>Multiple filters → Multiple output channels:</strong></p>
<p>If we want 64 output channels, we need 64 separate filters, each with shape 3×3×3. Total parameters: 64 × (27 + 1) = <strong>1,792</strong>.</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-2-1"><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a><span class="n">conv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span>
</span><span id="__span-2-2"><a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a>    <span class="n">in_channels</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>      <span class="c1"># RGB input</span>
</span><span id="__span-2-3"><a id="__codelineno-2-3" name="__codelineno-2-3" href="#__codelineno-2-3"></a>    <span class="n">out_channels</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>    <span class="c1"># Number of filters</span>
</span><span id="__span-2-4"><a id="__codelineno-2-4" name="__codelineno-2-4" href="#__codelineno-2-4"></a>    <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>      <span class="c1"># 3×3 filter</span>
</span><span id="__span-2-5"><a id="__codelineno-2-5" name="__codelineno-2-5" href="#__codelineno-2-5"></a>    <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="__span-2-6"><a id="__codelineno-2-6" name="__codelineno-2-6" href="#__codelineno-2-6"></a>    <span class="n">padding</span><span class="o">=</span><span class="mi">1</span>
</span><span id="__span-2-7"><a id="__codelineno-2-7" name="__codelineno-2-7" href="#__codelineno-2-7"></a><span class="p">)</span>
</span></code></pre></div>
<h3 id="what-filters-learn">What Filters Learn<a class="headerlink" href="#what-filters-learn" title="Permanent link">&para;</a></h3>
<p>Filters automatically learn features through training:</p>
<ul>
<li><strong>Early layers</strong>: Edges, colors, simple textures</li>
<li><strong>Middle layers</strong>: Textures, patterns, shapes</li>
<li><strong>Deep layers</strong>: Object parts, semantic concepts</li>
</ul>
<p>The first layer might learn vertical edges, horizontal edges, color gradients. The second combines those into textures. The third combines textures into shapes. This is <strong>hierarchical feature learning</strong>.</p>
<p><strong>Hierarchy emerges automatically</strong>: You don't design what each layer learns. Early layers only see raw pixels (can only learn edges); deep layers receive processed representations (can combine into complex features). When researchers visualize trained networks, they find edges in layer 1, textures in layers 2-3, object parts in mid-layers—discovered, not programmed.</p>
<h3 id="pooling-layers">Pooling Layers<a class="headerlink" href="#pooling-layers" title="Permanent link">&para;</a></h3>
<p>After convolution, we reduce spatial dimensions with pooling.</p>
<p><strong>Max Pooling</strong>: Take maximum value in each patch
- Reduces spatial dimensions (224 → 112 → 56...)
- Adds translation invariance—slight shifts don't change output
- Keeps strongest activations</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-3-1"><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a><span class="n">pool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</span><span id="__span-3-2"><a id="__codelineno-3-2" name="__codelineno-3-2" href="#__codelineno-3-2"></a><span class="c1"># 224×224 → 112×112</span>
</span></code></pre></div>
<p>A 2×2 max pool with stride 2 halves each dimension.</p>
<h3 id="classic-cnn-pattern">Classic CNN Pattern<a class="headerlink" href="#classic-cnn-pattern" title="Permanent link">&para;</a></h3>
<p><img alt="CNN Pipeline" src="../../assets/module7/cnn_pipeline.png" /></p>
<p><img alt="CNN Pipeline" src="../../assets/module7/cnn_pipeline.png" /></p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-4-1"><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a><span class="k">class</span><span class="w"> </span><span class="nc">SimpleCNN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="__span-4-2"><a id="__codelineno-4-2" name="__codelineno-4-2" href="#__codelineno-4-2"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
</span><span id="__span-4-3"><a id="__codelineno-4-3" name="__codelineno-4-3" href="#__codelineno-4-3"></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="__span-4-4"><a id="__codelineno-4-4" name="__codelineno-4-4" href="#__codelineno-4-4"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span><span id="__span-4-5"><a id="__codelineno-4-5" name="__codelineno-4-5" href="#__codelineno-4-5"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span><span id="__span-4-6"><a id="__codelineno-4-6" name="__codelineno-4-6" href="#__codelineno-4-6"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span><span id="__span-4-7"><a id="__codelineno-4-7" name="__codelineno-4-7" href="#__codelineno-4-7"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">pool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</span><span id="__span-4-8"><a id="__codelineno-4-8" name="__codelineno-4-8" href="#__codelineno-4-8"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span> <span class="o">*</span> <span class="mi">4</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">512</span><span class="p">)</span>
</span><span id="__span-4-9"><a id="__codelineno-4-9" name="__codelineno-4-9" href="#__codelineno-4-9"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
</span><span id="__span-4-10"><a id="__codelineno-4-10" name="__codelineno-4-10" href="#__codelineno-4-10"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>
</span><span id="__span-4-11"><a id="__codelineno-4-11" name="__codelineno-4-11" href="#__codelineno-4-11"></a>
</span><span id="__span-4-12"><a id="__codelineno-4-12" name="__codelineno-4-12" href="#__codelineno-4-12"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
</span><span id="__span-4-13"><a id="__codelineno-4-13" name="__codelineno-4-13" href="#__codelineno-4-13"></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
</span><span id="__span-4-14"><a id="__codelineno-4-14" name="__codelineno-4-14" href="#__codelineno-4-14"></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
</span><span id="__span-4-15"><a id="__codelineno-4-15" name="__codelineno-4-15" href="#__codelineno-4-15"></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv3</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
</span><span id="__span-4-16"><a id="__codelineno-4-16" name="__codelineno-4-16" href="#__codelineno-4-16"></a>        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Flatten</span>
</span><span id="__span-4-17"><a id="__codelineno-4-17" name="__codelineno-4-17" href="#__codelineno-4-17"></a>        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</span><span id="__span-4-18"><a id="__codelineno-4-18" name="__codelineno-4-18" href="#__codelineno-4-18"></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="__span-4-19"><a id="__codelineno-4-19" name="__codelineno-4-19" href="#__codelineno-4-19"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span></code></pre></div>
<h3 id="parameter-efficiency">Parameter Efficiency<a class="headerlink" href="#parameter-efficiency" title="Permanent link">&para;</a></h3>
<p><strong>For 32×32 RGB image, 64 outputs:</strong></p>
<table>
<thead>
<tr>
<th>Layer Type</th>
<th>Parameters</th>
</tr>
</thead>
<tbody>
<tr>
<td>Fully Connected</td>
<td>196,672</td>
</tr>
<tr>
<td>Conv2d (3×3)</td>
<td>1,792</td>
</tr>
</tbody>
</table>
<p><strong>~100x fewer parameters!</strong></p>
<p>Why?
1. <strong>Local connectivity</strong>: Each neuron connects only to a small patch
2. <strong>Weight sharing</strong>: Same filter applied everywhere</p>
<h3 id="historical-architectures">Historical Architectures<a class="headerlink" href="#historical-architectures" title="Permanent link">&para;</a></h3>
<p><strong>AlexNet (2012)</strong>: 8 layers, ReLU, dropout, GPU training. The breakthrough.</p>
<p><strong>VGG (2014)</strong>: 16-19 layers, all 3×3 convolutions. Showed depth matters.</p>
<p><strong>ResNet (2015)</strong>: Skip connections enabling 150+ layers.</p>
<h3 id="skip-residual-connections">Skip (Residual) Connections<a class="headerlink" href="#skip-residual-connections" title="Permanent link">&para;</a></h3>
<p><strong>The problem</strong>: Very deep networks suffer from vanishing gradients.</p>
<p><strong>The solution</strong>: Add the input directly to the output.</p>
<div class="arithmatex">\[Output = F(x) + x\]</div>
<div class="language-python highlight"><pre><span></span><code><span id="__span-5-1"><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a><span class="k">class</span><span class="w"> </span><span class="nc">ResidualBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="__span-5-2"><a id="__codelineno-5-2" name="__codelineno-5-2" href="#__codelineno-5-2"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">channels</span><span class="p">):</span>
</span><span id="__span-5-3"><a id="__codelineno-5-3" name="__codelineno-5-3" href="#__codelineno-5-3"></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="__span-5-4"><a id="__codelineno-5-4" name="__codelineno-5-4" href="#__codelineno-5-4"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">channels</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span><span id="__span-5-5"><a id="__codelineno-5-5" name="__codelineno-5-5" href="#__codelineno-5-5"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">bn1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">channels</span><span class="p">)</span>
</span><span id="__span-5-6"><a id="__codelineno-5-6" name="__codelineno-5-6" href="#__codelineno-5-6"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">channels</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span><span id="__span-5-7"><a id="__codelineno-5-7" name="__codelineno-5-7" href="#__codelineno-5-7"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">bn2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">channels</span><span class="p">)</span>
</span><span id="__span-5-8"><a id="__codelineno-5-8" name="__codelineno-5-8" href="#__codelineno-5-8"></a>
</span><span id="__span-5-9"><a id="__codelineno-5-9" name="__codelineno-5-9" href="#__codelineno-5-9"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
</span><span id="__span-5-10"><a id="__codelineno-5-10" name="__codelineno-5-10" href="#__codelineno-5-10"></a>        <span class="n">residual</span> <span class="o">=</span> <span class="n">x</span>
</span><span id="__span-5-11"><a id="__codelineno-5-11" name="__codelineno-5-11" href="#__codelineno-5-11"></a>        <span class="n">out</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bn1</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
</span><span id="__span-5-12"><a id="__codelineno-5-12" name="__codelineno-5-12" href="#__codelineno-5-12"></a>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn2</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">out</span><span class="p">))</span>
</span><span id="__span-5-13"><a id="__codelineno-5-13" name="__codelineno-5-13" href="#__codelineno-5-13"></a>        <span class="n">out</span> <span class="o">+=</span> <span class="n">residual</span>  <span class="c1"># Skip connection</span>
</span><span id="__span-5-14"><a id="__codelineno-5-14" name="__codelineno-5-14" href="#__codelineno-5-14"></a>        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</span></code></pre></div>
<p>If the network can't improve on the input, it can at least pass it through unchanged. This creates direct paths for gradients and enables training 100+ layer networks.</p>
<p><strong>Skip connection trade-offs</strong>: Memory overhead (must store earlier activations) and architectural constraints (dimensions must match, may need 1×1 convolutions). In shallow networks (3-5 layers), minimal benefit—skip connections solve a deep network problem. For networks &gt;10 layers, skip connections almost always help and are now considered essential in modern architectures.</p>
<h3 id="common-misconceptions">Common Misconceptions<a class="headerlink" href="#common-misconceptions" title="Permanent link">&para;</a></h3>
<table>
<thead>
<tr>
<th>Misconception</th>
<th>Reality</th>
</tr>
</thead>
<tbody>
<tr>
<td>"CNNs only work for images"</td>
<td>CNNs work on any grid data: audio, time series, etc.</td>
</tr>
<tr>
<td>"Deeper is always better"</td>
<td>Without skip connections, very deep nets fail. Architecture matters.</td>
</tr>
<tr>
<td>"You need to design CNNs from scratch"</td>
<td>Transfer learning is usually better.</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="73-transfer-learning">7.3 Transfer Learning<a class="headerlink" href="#73-transfer-learning" title="Permanent link">&para;</a></h2>
<h3 id="the-core-idea">The Core Idea<a class="headerlink" href="#the-core-idea" title="Permanent link">&para;</a></h3>
<p>Pre-trained ImageNet models learned <strong>general visual features</strong>: edges, textures, shapes, patterns. These features are useful for almost any image task!</p>
<p><strong>Two approaches:</strong>
1. <strong>Feature extraction</strong>: Freeze pre-trained layers, train only new classifier
2. <strong>Fine-tuning</strong>: Train all layers, but with lower learning rate for pre-trained layers</p>
<p>This is how most real-world computer vision is done. You rarely train from scratch anymore.</p>
<h3 id="feature-extraction">Feature Extraction<a class="headerlink" href="#feature-extraction" title="Permanent link">&para;</a></h3>
<p><strong>Freeze pre-trained layers, train only new classifier.</strong></p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-6-1"><a id="__codelineno-6-1" name="__codelineno-6-1" href="#__codelineno-6-1"></a><span class="kn">import</span><span class="w"> </span><span class="nn">torchvision.models</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">models</span>
</span><span id="__span-6-2"><a id="__codelineno-6-2" name="__codelineno-6-2" href="#__codelineno-6-2"></a>
</span><span id="__span-6-3"><a id="__codelineno-6-3" name="__codelineno-6-3" href="#__codelineno-6-3"></a><span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet50</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="__span-6-4"><a id="__codelineno-6-4" name="__codelineno-6-4" href="#__codelineno-6-4"></a>
</span><span id="__span-6-5"><a id="__codelineno-6-5" name="__codelineno-6-5" href="#__codelineno-6-5"></a><span class="c1"># Freeze all layers</span>
</span><span id="__span-6-6"><a id="__codelineno-6-6" name="__codelineno-6-6" href="#__codelineno-6-6"></a><span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
</span><span id="__span-6-7"><a id="__codelineno-6-7" name="__codelineno-6-7" href="#__codelineno-6-7"></a>    <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="__span-6-8"><a id="__codelineno-6-8" name="__codelineno-6-8" href="#__codelineno-6-8"></a>
</span><span id="__span-6-9"><a id="__codelineno-6-9" name="__codelineno-6-9" href="#__codelineno-6-9"></a><span class="c1"># Replace final classifier</span>
</span><span id="__span-6-10"><a id="__codelineno-6-10" name="__codelineno-6-10" href="#__codelineno-6-10"></a><span class="n">model</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">fc</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
</span><span id="__span-6-11"><a id="__codelineno-6-11" name="__codelineno-6-11" href="#__codelineno-6-11"></a>
</span><span id="__span-6-12"><a id="__codelineno-6-12" name="__codelineno-6-12" href="#__codelineno-6-12"></a><span class="c1"># Only train new classifier</span>
</span><span id="__span-6-13"><a id="__codelineno-6-13" name="__codelineno-6-13" href="#__codelineno-6-13"></a><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">fc</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>
</span></code></pre></div>
<p>The pre-trained ResNet extracts features. You just train a simple classifier on top.</p>
<h3 id="fine-tuning">Fine-Tuning<a class="headerlink" href="#fine-tuning" title="Permanent link">&para;</a></h3>
<p><strong>Train pre-trained layers with lower learning rate.</strong></p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-7-1"><a id="__codelineno-7-1" name="__codelineno-7-1" href="#__codelineno-7-1"></a><span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet50</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="__span-7-2"><a id="__codelineno-7-2" name="__codelineno-7-2" href="#__codelineno-7-2"></a><span class="n">model</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">fc</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
</span><span id="__span-7-3"><a id="__codelineno-7-3" name="__codelineno-7-3" href="#__codelineno-7-3"></a>
</span><span id="__span-7-4"><a id="__codelineno-7-4" name="__codelineno-7-4" href="#__codelineno-7-4"></a><span class="c1"># Different learning rates</span>
</span><span id="__span-7-5"><a id="__codelineno-7-5" name="__codelineno-7-5" href="#__codelineno-7-5"></a><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">([</span>
</span><span id="__span-7-6"><a id="__codelineno-7-6" name="__codelineno-7-6" href="#__codelineno-7-6"></a>    <span class="p">{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">layer4</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="mf">1e-4</span><span class="p">},</span>
</span><span id="__span-7-7"><a id="__codelineno-7-7" name="__codelineno-7-7" href="#__codelineno-7-7"></a>    <span class="p">{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">fc</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="mf">1e-3</span><span class="p">}</span>
</span><span id="__span-7-8"><a id="__codelineno-7-8" name="__codelineno-7-8" href="#__codelineno-7-8"></a><span class="p">])</span>
</span></code></pre></div>
<p>Pre-trained layers get smaller learning rate (they're already good). New layers get larger learning rate.</p>
<h3 id="when-to-use-which">When to Use Which<a class="headerlink" href="#when-to-use-which" title="Permanent link">&para;</a></h3>
<table>
<thead>
<tr>
<th>Dataset Size</th>
<th>Similarity to ImageNet</th>
<th>Approach</th>
</tr>
</thead>
<tbody>
<tr>
<td>Small</td>
<td>High</td>
<td>Feature extraction</td>
</tr>
<tr>
<td>Small</td>
<td>Low</td>
<td>Light fine-tuning</td>
</tr>
<tr>
<td>Large</td>
<td>High</td>
<td>Fine-tuning</td>
</tr>
<tr>
<td>Large</td>
<td>Low</td>
<td>Train from scratch</td>
</tr>
</tbody>
</table>
<p><strong>Example</strong>: You have 500 X-ray images. Train from scratch or transfer learning?</p>
<p>Transfer learning! 500 images isn't enough to train from scratch. Even though X-rays look different from ImageNet photos, early-layer features (edges, textures) are still useful.</p>
<p><strong>How similar is "similar enough"?</strong> There's no bright line—empirically test: train a classifier on frozen pre-trained features vs. random features. If pre-trained beats random, transfer helps. Even domains that seem "completely different" (medical imaging, industrial defects) usually benefit. Start with transfer learning, try fine-tuning if unsatisfactory, consider training from scratch only with millions of examples AND truly foreign image statistics.</p>
<h3 id="business-value-of-transfer-learning">Business Value of Transfer Learning<a class="headerlink" href="#business-value-of-transfer-learning" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>Cost savings</strong>: Days of training → hours</li>
<li><strong>Data efficiency</strong>: Good results with hundreds of images (not millions)</li>
<li><strong>Time to deployment</strong>: Quick proof-of-concept</li>
<li><strong>No massive compute</strong>: Fine-tuning on a laptop is possible</li>
</ul>
<hr />
<h2 id="74-modern-vision-applications">7.4 Modern Vision Applications<a class="headerlink" href="#74-modern-vision-applications" title="Permanent link">&para;</a></h2>
<h3 id="object-detection">Object Detection<a class="headerlink" href="#object-detection" title="Permanent link">&para;</a></h3>
<p><strong>Task</strong>: Find objects AND their locations (bounding boxes)</p>
<p>Not just "there's a dog" but "there's a dog at coordinates (x, y, w, h)."</p>
<p><strong>Key architectures:</strong>
- <strong>YOLO</strong>: Fast, single-pass detection ("You Only Look Once")
- <strong>Faster R-CNN</strong>: Two-stage, more accurate but slower</p>
<p><strong>Applications</strong>: Autonomous vehicles, security cameras, retail inventory</p>
<h3 id="image-segmentation">Image Segmentation<a class="headerlink" href="#image-segmentation" title="Permanent link">&para;</a></h3>
<p><strong>Semantic segmentation</strong>: Label every pixel with a class (road, car, person)</p>
<p><strong>Instance segmentation</strong>: Separate individual objects (this car vs that car)</p>
<p><strong>Key architecture</strong>: U-Net—encoder-decoder with skip connections</p>
<p><strong>Applications</strong>: Medical imaging, autonomous driving, photo editing</p>
<h3 id="vision-transformers-vit">Vision Transformers (ViT)<a class="headerlink" href="#vision-transformers-vit" title="Permanent link">&para;</a></h3>
<p>The latest revolution: apply transformer architecture to images.</p>
<p><strong>How it works:</strong>
1. Split image into 16×16 patches
2. Flatten patches into sequences
3. Apply transformer encoder (same architecture as NLP!)</p>
<p><strong>Why it matters:</strong>
- State-of-the-art on many benchmarks
- Unified architecture for vision AND language
- Enables CLIP, DALL-E, multimodal AI</p>
<h3 id="business-applications">Business Applications<a class="headerlink" href="#business-applications" title="Permanent link">&para;</a></h3>
<table>
<thead>
<tr>
<th>Industry</th>
<th>Application</th>
</tr>
</thead>
<tbody>
<tr>
<td>Retail</td>
<td>Inventory monitoring, checkout-free stores</td>
</tr>
<tr>
<td>Manufacturing</td>
<td>Defect detection, quality control</td>
</tr>
<tr>
<td>Healthcare</td>
<td>Radiology, pathology analysis</td>
</tr>
<tr>
<td>Agriculture</td>
<td>Crop monitoring, disease detection</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="reflection-questions">Reflection Questions<a class="headerlink" href="#reflection-questions" title="Permanent link">&para;</a></h2>
<ol>
<li>
<p>An image is 1000×1000 pixels RGB. How many input features? Why is this problematic for fully connected networks?</p>
</li>
<li>
<p>If you shift a cat 10 pixels to the right, how would a fully connected network's perception change vs. a CNN?</p>
</li>
<li>
<p>A 3×3 conv filter has 9 weights per channel. How does this compare to fully connected for the same output?</p>
</li>
<li>
<p>After 3 max pooling layers of 2×2, what happens to a 224×224 image?</p>
</li>
<li>
<p>How do skip connections help train very deep networks?</p>
</li>
<li>
<p>You have 500 X-ray images. Train from scratch or transfer learning? Why?</p>
</li>
<li>
<p>Why fine-tune later layers before earlier layers?</p>
</li>
</ol>
<hr />
<h2 id="practice-problems">Practice Problems<a class="headerlink" href="#practice-problems" title="Permanent link">&para;</a></h2>
<ol>
<li>
<p>Calculate output size: 64×64 input, 3×3 kernel, stride=1, padding=0</p>
</li>
<li>
<p>Calculate parameters: Conv2d with in_channels=32, out_channels=64, kernel_size=3</p>
</li>
<li>
<p>Design a CNN for 28×28 grayscale images (MNIST) with 3 conv layers</p>
</li>
<li>
<p>Set up transfer learning code for a 5-class classification problem using ResNet18</p>
</li>
<li>
<p>Explain why a 7×7 filter might be replaced by two 3×3 filters</p>
</li>
</ol>
<hr />
<h2 id="chapter-summary">Chapter Summary<a class="headerlink" href="#chapter-summary" title="Permanent link">&para;</a></h2>
<p><strong>Six key takeaways from Module 7:</strong></p>
<ol>
<li>
<p><strong>Images</strong> are high-dimensional; FC networks don't scale</p>
</li>
<li>
<p><strong>CNNs</strong> use local filters with weight sharing (100x fewer parameters)</p>
</li>
<li>
<p><strong>Pooling</strong> reduces dimensions and adds translation invariance</p>
</li>
<li>
<p><strong>Skip connections</strong> enable training very deep networks</p>
</li>
<li>
<p><strong>Transfer learning</strong> is usually better than training from scratch</p>
</li>
<li>
<p><strong>Modern CV</strong>: detection, segmentation, Vision Transformers</p>
</li>
</ol>
<hr />
<h2 id="whats-next">What's Next<a class="headerlink" href="#whats-next" title="Permanent link">&para;</a></h2>
<p>In Module 8, we tackle <strong>Natural Language Processing</strong>:
- Text as sequences
- Word embeddings
- Transformers and attention
- Pre-trained language models</p>
<p>Vision Transformers connect both domains—the same architecture that powers GPT and BERT can also process images!</p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "../..", "features": ["navigation.instant", "navigation.tracking", "navigation.sections", "navigation.expand", "navigation.top", "search.suggest", "search.highlight", "content.code.copy"], "search": "../../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.79ae519e.min.js"></script>
      
        <script src="../../javascripts/mathjax.js"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>